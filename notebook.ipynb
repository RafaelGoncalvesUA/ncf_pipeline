{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkFiles\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/rafael/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrfg\u001b[0m (\u001b[33mrafaelgoncalvesua\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rafael/Documentos/CAA/Project2/wandb/run-20240615_015924-cjam9v8r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rafaelgoncalvesua/proj-caa-2/runs/cjam9v8r' target=\"_blank\">fiery-forest-3</a></strong> to <a href='https://wandb.ai/rafaelgoncalvesua/proj-caa-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rafaelgoncalvesua/proj-caa-2' target=\"_blank\">https://wandb.ai/rafaelgoncalvesua/proj-caa-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rafaelgoncalvesua/proj-caa-2/runs/cjam9v8r' target=\"_blank\">https://wandb.ai/rafaelgoncalvesua/proj-caa-2/runs/cjam9v8r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rafaelgoncalvesua/proj-caa-2/runs/cjam9v8r?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7119fbd83430>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"1bf6d96598e920a3fe32392d71154f5e9011cdbd\", relogin=True)\n",
    "wandb.init(project=\"proj-caa-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_TOPIC = \"movielens\"\n",
    "KAFKA_BOOTSTRAP_SERVER = \"localhost:9092\"\n",
    "MODEL_NAME = \"non_linear\"\n",
    "NUM_USERS = 162541\n",
    "NUM_MOVIES = 59047\n",
    "EMBEDDING_DIM = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/15 01:59:27 WARN Utils: Your hostname, omen resolves to a loopback address: 127.0.1.1; using 192.168.1.122 instead (on interface wlo1)\n",
      "24/06/15 01:59:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/rafael/Documentos/CAA/Project2/venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/rafael/.ivy2/cache\n",
      "The jars for the packages stored in: /home/rafael/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7c9ca5d2-6977-4565-8096-083d3716f5dc;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.3 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      ":: resolution report :: resolve 534ms :: artifacts dl 21ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   11  |   0   |   0   |   0   ||   11  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7c9ca5d2-6977-4565-8096-083d3716f5dc\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 11 already retrieved (0kB/15ms)\n",
      "24/06/15 01:59:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.config(\n",
    "        \"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\"\n",
    "    )\n",
    "    .appName(\"recommender\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = (\n",
    "    spark.readStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option(\"subscribe\", KAFKA_TOPIC)\n",
    "    .option(\"startingOffsets\", \"latest\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "data = (\n",
    "    raw_data.selectExpr(\"CAST(value AS STRING) as value\")\n",
    "    .select(\n",
    "        from_json(\n",
    "            \"value\", \"userId INT, movieId INT, rating DOUBLE, timestamp INT\"\n",
    "        ).alias(\"data\")\n",
    "    )\n",
    "    .select(\"data.*\")  # unpack dict\n",
    "    .selectExpr(\"userId\", \"movieId\", \"rating\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, ratings):\n",
    "        self.users = ratings['userId'].values\n",
    "        self.items = ratings['movieId'].values\n",
    "        self.ratings = ratings['rating'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.users[idx], self.items[idx], self.ratings[idx])\n",
    "    \n",
    "class CollaborativeFilteringModel(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        \n",
    "        super(CollaborativeFilteringModel, self).__init__()\n",
    "        self.user_embedding = torch.nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = torch.nn.Embedding(num_items, embedding_dim)\n",
    "        self.fc1 = torch.nn.Linear(embedding_dim * 2, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 1)\n",
    "\n",
    "        self.criterion = torch.nn.MSELoss()\n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "    \n",
    "    def forward(self, user_ids, item_ids):\n",
    "        if torch.any(user_ids >= self.user_embedding.num_embeddings):\n",
    "            raise ValueError(f\"user_ids contain indices outside the range: {user_ids} | {self.user_embedding.num_embeddings}\")\n",
    "        if torch.any(item_ids >= self.item_embedding.num_embeddings):\n",
    "            raise ValueError(f\"item_ids contain indices outside the range: {item_ids} | {self.item_embedding.num_embeddings}\")\n",
    "\n",
    "        user_embeds = self.user_embedding(user_ids)\n",
    "        item_embeds = self.item_embedding(item_ids)\n",
    "        x = torch.cat([user_embeds, item_embeds], dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def train_(self, train_loader):\n",
    "        self.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for user_ids, item_ids, ratings in train_loader:\n",
    "            user_ids, item_ids, ratings = user_ids.to(self.device), item_ids.to(self.device), ratings.to(self.device).float()\n",
    "            ratings = ratings.float().view(-1, 1)\n",
    "\n",
    "            self.optim.zero_grad()\n",
    "            predictions = self(user_ids, item_ids)\n",
    "            loss = self.criterion(predictions, ratings)\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(train_loader)\n",
    "    \n",
    "    def evaluate(self, test_loader):\n",
    "        self.eval()\n",
    "        total_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for user_ids, item_ids, ratings in test_loader:\n",
    "                user_ids, item_ids, ratings = user_ids.to(self.device), item_ids.to(self.device), ratings.to(self.device).float()\n",
    "                ratings = ratings.float().view(-1, 1)\n",
    "\n",
    "                predictions = self(user_ids, item_ids)\n",
    "                loss = self.criterion(predictions, ratings)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(test_loader)\n",
    "\n",
    "    \n",
    "    def fit(self, train_loader, val_loader, test_loader=None, num_epochs=10):\n",
    "        # self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.device = torch.device('cpu')\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = self.train_(train_loader)\n",
    "            val_loss = self.evaluate(val_loader)\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "            wandb.log({\"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "\n",
    "        if test_loader:\n",
    "            test_loss = self.evaluate(test_loader)\n",
    "            print(f'Test Loss: {test_loss}')\n",
    "            wandb.log({\"test_loss\": test_loss})\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CollaborativeFilteringModel(NUM_USERS, NUM_MOVIES, EMBEDDING_DIM)\n",
    "\n",
    "# save torch model\n",
    "torch.save(model.state_dict(), f\"models/{MODEL_NAME}.pth\")\n",
    "\n",
    "# load torch model\n",
    "model.load_state_dict(torch.load(f\"models/{MODEL_NAME}.pth\"))\n",
    "\n",
    "# broadcast data buffer\n",
    "broad_data_buffer = sc.broadcast([])\n",
    "\n",
    "# static test dataset and user/item index mapping\n",
    "test_df = pd.read_csv(\"data/ratings_test.csv\")\n",
    "user2idx = {user: idx for idx, user in enumerate(test_df['userId'].unique())}\n",
    "item2idx = {item: idx for idx, item in enumerate(test_df['movieId'].unique())}\n",
    "\n",
    "test_df['userId'] = test_df['userId'].map(user2idx)\n",
    "test_df['movieId'] = test_df['movieId'].map(item2idx)\n",
    "test_loader = DataLoader(MovieLensDataset(test_df), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH 0] Empty batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH 1] Current buffer size: 2000\n",
      "[BATCH 2] Current buffer size: 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BATCH 3] Model loaded\n",
      "[BATCH 3] Data loaded\n",
      "[BATCH 3] Fitting Model\n",
      "Epoch 1/10, Loss: 2.7856151593243417, Val Loss: 1.418178610685395\n",
      "Epoch 2/10, Loss: 1.2810803498227172, Val Loss: 1.3542559001503922\n",
      "Epoch 3/10, Loss: 1.198266336157278, Val Loss: 1.3303112213204547\n",
      "Epoch 4/10, Loss: 1.1386875210364171, Val Loss: 1.3023858215750717\n",
      "Epoch 5/10, Loss: 1.090739487138994, Val Loss: 1.2961150349640265\n",
      "Epoch 6/10, Loss: 1.058551635478903, Val Loss: 1.2939593632046769\n",
      "Epoch 7/10, Loss: 1.0248008900624843, Val Loss: 1.2797560720908931\n",
      "Epoch 8/10, Loss: 0.9909287171861145, Val Loss: 1.2921760939970248\n",
      "Epoch 9/10, Loss: 0.9570004431747952, Val Loss: 1.308965182885891\n",
      "Epoch 10/10, Loss: 0.9225196428825518, Val Loss: 1.2884252987256863\n",
      "Test Loss: 1.2194591492951063\n",
      "[BATCH 3] Model fitted\n",
      "[BATCH 3] Model saved\n",
      "[BATCH 4] Current buffer size: 6000\n",
      "[BATCH 5] Model loaded\n",
      "[BATCH 5] Data loaded\n",
      "[BATCH 5] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1991066281000773, Val Loss: 1.1606443242022866\n",
      "Epoch 2/10, Loss: 1.1029906618595122, Val Loss: 1.1245783990935276\n",
      "Epoch 3/10, Loss: 1.0424888948599498, Val Loss: 1.1335039781896692\n",
      "Epoch 4/10, Loss: 1.005654833316803, Val Loss: 1.1119906306266785\n",
      "Epoch 5/10, Loss: 0.966936149597168, Val Loss: 1.1275168406335931\n",
      "Epoch 6/10, Loss: 0.9284515225887299, Val Loss: 1.128265978474366\n",
      "Epoch 7/10, Loss: 0.8798914917310079, Val Loss: 1.1426447065253007\n",
      "Epoch 8/10, Loss: 0.8328107941150665, Val Loss: 1.1499672688935931\n",
      "Epoch 9/10, Loss: 0.7859553730487824, Val Loss: 1.1842278116627742\n",
      "Epoch 10/10, Loss: 0.7302558467785517, Val Loss: 1.189549367678793\n",
      "Test Loss: 1.237622149912344\n",
      "[BATCH 5] Model fitted\n",
      "[BATCH 5] Model saved\n",
      "[BATCH 6] Current buffer size: 5000\n",
      "[BATCH 7] Model loaded\n",
      "[BATCH 7] Data loaded\n",
      "[BATCH 7] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1731894724610923, Val Loss: 1.2380011541502816\n",
      "Epoch 2/10, Loss: 1.0420545711033586, Val Loss: 1.2237773469516209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rafael/Documentos/CAA/Project2/venv/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/rafael/Documentos/CAA/Project2/venv/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 68\u001b[0m\n\u001b[1;32m     59\u001b[0m     broad_data_buffer \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mbroadcast([])\n\u001b[1;32m     62\u001b[0m query \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     63\u001b[0m     data\u001b[38;5;241m.\u001b[39mwriteStream\u001b[38;5;241m.\u001b[39mtrigger(processingTime\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m60 seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;241m.\u001b[39mforeachBatch(fine_tune)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 68\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/CAA/Project2/venv/lib/python3.10/site-packages/pyspark/sql/streaming/query.py:221\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documentos/CAA/Project2/venv/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/Documentos/CAA/Project2/venv/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/Documentos/CAA/Project2/venv/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.9757293415242347, Val Loss: 1.232354007448469\n",
      "Epoch 4/10, Loss: 0.9236061322516289, Val Loss: 1.2108759726796832\n",
      "Epoch 5/10, Loss: 0.8775900053805199, Val Loss: 1.2336673395974296\n",
      "Epoch 6/10, Loss: 0.8273890716010246, Val Loss: 1.2446716615131923\n",
      "Epoch 7/10, Loss: 0.7742068385300429, Val Loss: 1.2652670792170932\n",
      "Epoch 8/10, Loss: 0.721555026329082, Val Loss: 1.2974375213895526\n",
      "Epoch 9/10, Loss: 0.668317010221274, Val Loss: 1.331337457043784\n",
      "Epoch 10/10, Loss: 0.6081610272328059, Val Loss: 1.3677057198115758\n",
      "Test Loss: 1.2853894289142698\n",
      "[BATCH 7] Model fitted\n",
      "[BATCH 7] Model saved\n",
      "[BATCH 8] Current buffer size: 6000\n",
      "[BATCH 9] Model loaded\n",
      "[BATCH 9] Data loaded\n",
      "[BATCH 9] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1727715166409811, Val Loss: 1.1554991540155912\n",
      "Epoch 2/10, Loss: 1.0208570404847463, Val Loss: 1.1584658387460207\n",
      "Epoch 3/10, Loss: 0.9540578377246857, Val Loss: 1.153820552323994\n",
      "Epoch 4/10, Loss: 0.9029183801015218, Val Loss: 1.165286969197424\n",
      "Epoch 5/10, Loss: 0.8524583323796591, Val Loss: 1.173367103463725\n",
      "Epoch 6/10, Loss: 0.8009423847993214, Val Loss: 1.2141861162687604\n",
      "Epoch 7/10, Loss: 0.7423983705043793, Val Loss: 1.2006616043417078\n",
      "Epoch 8/10, Loss: 0.6926880808671315, Val Loss: 1.2437258237286617\n",
      "Epoch 9/10, Loss: 0.6361888680855433, Val Loss: 1.258709170316395\n",
      "Epoch 10/10, Loss: 0.5830168739954631, Val Loss: 1.2850331224893268\n",
      "Test Loss: 1.2589399684298435\n",
      "[BATCH 9] Model fitted\n",
      "[BATCH 9] Model saved\n",
      "[BATCH 10] Current buffer size: 5000\n",
      "[BATCH 11] Model loaded\n",
      "[BATCH 11] Data loaded\n",
      "[BATCH 11] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1743293115194293, Val Loss: 1.166468698637826\n",
      "Epoch 2/10, Loss: 1.0106184232062188, Val Loss: 1.1539572119712829\n",
      "Epoch 3/10, Loss: 0.930399389370628, Val Loss: 1.1429152250289918\n",
      "Epoch 4/10, Loss: 0.8724792197994564, Val Loss: 1.1878490958895003\n",
      "Epoch 5/10, Loss: 0.816010313189548, Val Loss: 1.2072918125561305\n",
      "Epoch 6/10, Loss: 0.7579372352448063, Val Loss: 1.205146963255746\n",
      "Epoch 7/10, Loss: 0.7020494242509207, Val Loss: 1.2326450279780796\n",
      "Epoch 8/10, Loss: 0.6430903604065162, Val Loss: 1.2564552681786674\n",
      "Epoch 9/10, Loss: 0.594436176661132, Val Loss: 1.2724071145057678\n",
      "Epoch 10/10, Loss: 0.5347351742827374, Val Loss: 1.3134341563497272\n",
      "Test Loss: 1.2727844627992582\n",
      "[BATCH 11] Model fitted\n",
      "[BATCH 11] Model saved\n",
      "[BATCH 12] Current buffer size: 6000\n",
      "[BATCH 13] Model loaded\n",
      "[BATCH 13] Data loaded\n",
      "[BATCH 13] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1813133748372395, Val Loss: 1.0558522657344216\n",
      "Epoch 2/10, Loss: 1.0034202718734742, Val Loss: 1.0578375521459078\n",
      "Epoch 3/10, Loss: 0.9233661848306656, Val Loss: 1.064317962056712\n",
      "Epoch 4/10, Loss: 0.865844811797142, Val Loss: 1.0711601611815\n",
      "Epoch 5/10, Loss: 0.8118181343873342, Val Loss: 1.077445365880665\n",
      "Epoch 6/10, Loss: 0.7582233264048894, Val Loss: 1.1026734976392043\n",
      "Epoch 7/10, Loss: 0.7058827710151673, Val Loss: 1.1518599736063104\n",
      "Epoch 8/10, Loss: 0.6554663201173146, Val Loss: 1.1435203850269318\n",
      "Epoch 9/10, Loss: 0.6002161931991578, Val Loss: 1.1750420253527791\n",
      "Epoch 10/10, Loss: 0.5417287673552831, Val Loss: 1.2077831202431728\n",
      "Test Loss: 1.2459071623120905\n",
      "[BATCH 13] Model fitted\n",
      "[BATCH 13] Model saved\n",
      "[BATCH 14] Current buffer size: 6000\n",
      "[BATCH 15] Model loaded\n",
      "[BATCH 15] Data loaded\n",
      "[BATCH 15] Fitting Model\n",
      "Epoch 1/10, Loss: 1.155959825584854, Val Loss: 1.0469689624650138\n",
      "Epoch 2/10, Loss: 0.9766528792139413, Val Loss: 1.0397196786744254\n",
      "Epoch 3/10, Loss: 0.8956903854142064, Val Loss: 1.0611606853348867\n",
      "Epoch 4/10, Loss: 0.8334033409322518, Val Loss: 1.0509825893810818\n",
      "Epoch 5/10, Loss: 0.7784195563931396, Val Loss: 1.0849400111607144\n",
      "Epoch 6/10, Loss: 0.7223626768243485, Val Loss: 1.0863543101719448\n",
      "Epoch 7/10, Loss: 0.6706664076317912, Val Loss: 1.092777006966727\n",
      "Epoch 8/10, Loss: 0.6130070964927259, Val Loss: 1.1302055971963065\n",
      "Epoch 9/10, Loss: 0.5654178767100625, Val Loss: 1.1669092110225132\n",
      "Epoch 10/10, Loss: 0.5194725182609282, Val Loss: 1.1939957312175207\n",
      "Test Loss: 1.2723405922636135\n",
      "[BATCH 15] Model fitted\n",
      "[BATCH 15] Model saved\n",
      "[BATCH 16] Current buffer size: 5966\n",
      "[BATCH 17] Model loaded\n",
      "[BATCH 17] Data loaded\n",
      "[BATCH 17] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1528442891438802, Val Loss: 1.1175374514178227\n",
      "Epoch 2/10, Loss: 0.9613639839490254, Val Loss: 1.08940778594268\n",
      "Epoch 3/10, Loss: 0.8848079677422841, Val Loss: 1.0892561752545207\n",
      "Epoch 4/10, Loss: 0.8192716131607691, Val Loss: 1.1040322921778027\n",
      "Epoch 5/10, Loss: 0.7621575339635214, Val Loss: 1.1280587629268044\n",
      "Epoch 6/10, Loss: 0.7056510049104691, Val Loss: 1.1517387189363177\n",
      "Epoch 7/10, Loss: 0.6545395259062449, Val Loss: 1.1590191141555184\n",
      "Epoch 8/10, Loss: 0.5974912889798483, Val Loss: 1.1801210924198753\n",
      "Epoch 9/10, Loss: 0.5438596868515014, Val Loss: 1.2372049297157086\n",
      "Epoch 10/10, Loss: 0.49785171667734784, Val Loss: 1.2711616236912577\n",
      "Test Loss: 1.2860804687782057\n",
      "[BATCH 17] Model fitted\n",
      "[BATCH 17] Model saved\n",
      "[BATCH 18] Current buffer size: 6000\n",
      "[BATCH 19] Model loaded\n",
      "[BATCH 19] Data loaded\n",
      "[BATCH 19] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1894737529754638, Val Loss: 1.0523856188121594\n",
      "Epoch 2/10, Loss: 1.0030012174447378, Val Loss: 1.0638036163229692\n",
      "Epoch 3/10, Loss: 0.9187521326541901, Val Loss: 1.044996749413641\n",
      "Epoch 4/10, Loss: 0.8448055251439412, Val Loss: 1.0682634350500608\n",
      "Epoch 5/10, Loss: 0.7789711407820383, Val Loss: 1.090515108484971\n",
      "Epoch 6/10, Loss: 0.7160905502239863, Val Loss: 1.1067697594040318\n",
      "Epoch 7/10, Loss: 0.6533147412538528, Val Loss: 1.1488355555032428\n",
      "Epoch 8/10, Loss: 0.5972590810060501, Val Loss: 1.186004638671875\n",
      "Epoch 9/10, Loss: 0.5349584919214249, Val Loss: 1.205606902900495\n",
      "Epoch 10/10, Loss: 0.4808842005332311, Val Loss: 1.2395342949189638\n",
      "Test Loss: 1.3040352509675635\n",
      "[BATCH 19] Model fitted\n",
      "[BATCH 19] Model saved\n",
      "[BATCH 20] Current buffer size: 6000\n",
      "[BATCH 21] Model loaded\n",
      "[BATCH 21] Data loaded\n",
      "[BATCH 21] Fitting Model\n",
      "Epoch 1/10, Loss: 1.174018533333488, Val Loss: 1.0740662557738168\n",
      "Epoch 2/10, Loss: 0.9668296316395635, Val Loss: 1.0512689113616944\n",
      "Epoch 3/10, Loss: 0.8773396421169889, Val Loss: 1.0414693542889186\n",
      "Epoch 4/10, Loss: 0.8050267806519633, Val Loss: 1.050343304021018\n",
      "Epoch 5/10, Loss: 0.7447654941807622, Val Loss: 1.0867275663784572\n",
      "Epoch 6/10, Loss: 0.6910505124192307, Val Loss: 1.0902161717414856\n",
      "Epoch 7/10, Loss: 0.6295042150262473, Val Loss: 1.1155833176204137\n",
      "Epoch 8/10, Loss: 0.5762478508379149, Val Loss: 1.1419251680374145\n",
      "Epoch 9/10, Loss: 0.5193969324447106, Val Loss: 1.1819071888923645\n",
      "Epoch 10/10, Loss: 0.45837418540664343, Val Loss: 1.2275158762931824\n",
      "Test Loss: 1.291193698270704\n",
      "[BATCH 21] Model fitted\n",
      "[BATCH 21] Model saved\n",
      "[BATCH 22] Current buffer size: 6000\n",
      "[BATCH 23] Model loaded\n",
      "[BATCH 23] Data loaded\n",
      "[BATCH 23] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1924863568941753, Val Loss: 1.1395739912986755\n",
      "Epoch 2/10, Loss: 0.9758551049232483, Val Loss: 1.1222223294408697\n",
      "Epoch 3/10, Loss: 0.8861069401105245, Val Loss: 1.1385122035679065\n",
      "Epoch 4/10, Loss: 0.8162288077672323, Val Loss: 1.1547455301410274\n",
      "Epoch 5/10, Loss: 0.7532244398196538, Val Loss: 1.1618597711387433\n",
      "Epoch 6/10, Loss: 0.6911529527107875, Val Loss: 1.2002122762956118\n",
      "Epoch 7/10, Loss: 0.6314849215745926, Val Loss: 1.2292131091419018\n",
      "Epoch 8/10, Loss: 0.5736896936098734, Val Loss: 1.2556210191626298\n",
      "Epoch 9/10, Loss: 0.5181008330980936, Val Loss: 1.3100627848976536\n",
      "Epoch 10/10, Loss: 0.46174686004718146, Val Loss: 1.3522435787476992\n",
      "Test Loss: 1.3141511506656502\n",
      "[BATCH 23] Model fitted\n",
      "[BATCH 23] Model saved\n",
      "[BATCH 24] Current buffer size: 6000\n",
      "[BATCH 25] Model loaded\n",
      "[BATCH 25] Data loaded\n",
      "[BATCH 25] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1930767186482747, Val Loss: 1.1125144127168154\n",
      "Epoch 2/10, Loss: 0.9689311671257019, Val Loss: 1.1156228655262996\n",
      "Epoch 3/10, Loss: 0.8862895627816518, Val Loss: 1.1038876677814282\n",
      "Epoch 4/10, Loss: 0.8131599601109822, Val Loss: 1.1231416071716107\n",
      "Epoch 5/10, Loss: 0.7542257024844488, Val Loss: 1.1481077247544338\n",
      "Epoch 6/10, Loss: 0.6980073153972626, Val Loss: 1.1764657858170962\n",
      "Epoch 7/10, Loss: 0.6442181609074275, Val Loss: 1.1995194632756083\n",
      "Epoch 8/10, Loss: 0.5833957787354788, Val Loss: 1.2263221615239193\n",
      "Epoch 9/10, Loss: 0.5308548591534297, Val Loss: 1.2738804926997738\n",
      "Epoch 10/10, Loss: 0.4704894236723582, Val Loss: 1.3378867099159641\n",
      "Test Loss: 1.2991245049534728\n",
      "[BATCH 25] Model fitted\n",
      "[BATCH 25] Model saved\n",
      "[BATCH 26] Current buffer size: 5000\n",
      "[BATCH 27] Model loaded\n",
      "[BATCH 27] Data loaded\n",
      "[BATCH 27] Fitting Model\n",
      "Epoch 1/10, Loss: 1.2078800663567972, Val Loss: 1.1422264984675816\n",
      "Epoch 2/10, Loss: 0.9845798577087513, Val Loss: 1.131325456074306\n",
      "Epoch 3/10, Loss: 0.8853555621876232, Val Loss: 1.1288354413849966\n",
      "Epoch 4/10, Loss: 0.8155599093955496, Val Loss: 1.156735716547285\n",
      "Epoch 5/10, Loss: 0.7546206855255625, Val Loss: 1.150383402620043\n",
      "Epoch 6/10, Loss: 0.6980415455241135, Val Loss: 1.1943364313670568\n",
      "Epoch 7/10, Loss: 0.6369997712149136, Val Loss: 1.2338485632623946\n",
      "Epoch 8/10, Loss: 0.580345053171766, Val Loss: 1.248063291822161\n",
      "Epoch 9/10, Loss: 0.5209895877734475, Val Loss: 1.3043596472058978\n",
      "Epoch 10/10, Loss: 0.4634253045786982, Val Loss: 1.3675305349486215\n",
      "Test Loss: 1.3358692812862651\n",
      "[BATCH 27] Model fitted\n",
      "[BATCH 27] Model saved\n",
      "[BATCH 28] Current buffer size: 6000\n",
      "[BATCH 29] Model loaded\n",
      "[BATCH 29] Data loaded\n",
      "[BATCH 29] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1497733477751415, Val Loss: 1.1164896645044025\n",
      "Epoch 2/10, Loss: 0.9195020083586375, Val Loss: 1.103331330575441\n",
      "Epoch 3/10, Loss: 0.833438406586647, Val Loss: 1.1425320678635646\n",
      "Epoch 4/10, Loss: 0.7673892084757487, Val Loss: 1.1149637918723256\n",
      "Epoch 5/10, Loss: 0.707083854675293, Val Loss: 1.1639999747276306\n",
      "Epoch 6/10, Loss: 0.6533574237426122, Val Loss: 1.1514336686385305\n",
      "Epoch 7/10, Loss: 0.597318960428238, Val Loss: 1.1951746124970286\n",
      "Epoch 8/10, Loss: 0.5458313010136286, Val Loss: 1.2323540590311353\n",
      "Epoch 9/10, Loss: 0.4941065667072932, Val Loss: 1.2806000019374646\n",
      "Epoch 10/10, Loss: 0.44305862913529076, Val Loss: 1.2987854606226872\n",
      "Test Loss: 1.2591921185504171\n",
      "[BATCH 29] Model fitted\n",
      "[BATCH 29] Model saved\n",
      "[BATCH 30] Current buffer size: 6000\n",
      "[BATCH 31] Model loaded\n",
      "[BATCH 31] Data loaded\n",
      "[BATCH 31] Fitting Model\n",
      "Epoch 1/10, Loss: 1.1407615911960602, Val Loss: 1.1596608867770748\n",
      "Epoch 2/10, Loss: 0.9355692573388418, Val Loss: 1.1513757768430208\n",
      "Epoch 3/10, Loss: 0.8454382493098577, Val Loss: 1.153926311354888\n",
      "Epoch 4/10, Loss: 0.7779325918356578, Val Loss: 1.1636930311981\n",
      "Epoch 5/10, Loss: 0.7151329517364502, Val Loss: 1.2085088397327222\n",
      "Epoch 6/10, Loss: 0.65273595114549, Val Loss: 1.2179219032588757\n",
      "Epoch 7/10, Loss: 0.595316038330396, Val Loss: 1.274588410791598\n",
      "Epoch 8/10, Loss: 0.5367846580346426, Val Loss: 1.2972731951035952\n",
      "Epoch 9/10, Loss: 0.4776454452673594, Val Loss: 1.353765556686803\n",
      "Epoch 10/10, Loss: 0.42044265965620675, Val Loss: 1.3845571593234414\n",
      "Test Loss: 1.3271509563519042\n",
      "[BATCH 31] Model fitted\n",
      "[BATCH 31] Model saved\n"
     ]
    }
   ],
   "source": [
    "# delete query 'ratings_' if it exists\n",
    "for q in spark.streams.active:\n",
    "    if q.name == \"ratings_\":\n",
    "        q.stop()\n",
    "\n",
    "\n",
    "def fine_tune(batch_df, batch_id):\n",
    "    if batch_df.count() == 0:\n",
    "        print(f\"[BATCH {batch_id}] Empty batch\")\n",
    "        return\n",
    "    \n",
    "    batch_pandas = batch_df.toPandas()\n",
    "\n",
    "    for user in batch_pandas[\"userId\"]:\n",
    "        if user not in user2idx:\n",
    "            user2idx[user] = len(user2idx)\n",
    "\n",
    "    for item in batch_pandas[\"movieId\"]:\n",
    "        if item not in item2idx:\n",
    "            item2idx[item] = len(item2idx)\n",
    "    \n",
    "    # update accumulated DataFrame with new batch as dict\n",
    "    global broad_data_buffer\n",
    "    broad_data_buffer.unpersist()\n",
    "    data_buffer = broad_data_buffer.value.copy()\n",
    "    data_buffer.extend(batch_pandas.to_dict(orient=\"records\"))\n",
    "\n",
    "    while len(data_buffer) < 10000:\n",
    "        broad_data_buffer = sc.broadcast(data_buffer)\n",
    "        print(f\"[BATCH {batch_id}] Current buffer size: {len(data_buffer)}\")\n",
    "        return\n",
    "\n",
    "    model.load_state_dict(torch.load(\"models/non_linear.pth\"))\n",
    "    print(f\"[BATCH {batch_id}] Model loaded\")\n",
    "\n",
    "    data_buffer_df = pd.DataFrame(data_buffer, index=None)\n",
    "    data_buffer_df[\"userId\"] = data_buffer_df[\"userId\"].map(user2idx)\n",
    "    data_buffer_df[\"movieId\"] = data_buffer_df[\"movieId\"].map(item2idx)\n",
    "\n",
    "    dataset = MovieLensDataset(data_buffer_df)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print(f\"[BATCH {batch_id}] Data loaded\")\n",
    "\n",
    "    print(f\"[BATCH {batch_id}] Fitting Model\")\n",
    "    model.fit(train_loader, val_loader, test_loader)\n",
    "    print(f\"[BATCH {batch_id}] Model fitted\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"models/{MODEL_NAME}.pth\")\n",
    "    print(f\"[BATCH {batch_id}] Model saved\")\n",
    "\n",
    "    # clear data buffer\n",
    "    broad_data_buffer = sc.broadcast([])\n",
    "    \n",
    "\n",
    "query = (\n",
    "    data.writeStream.trigger(processingTime=\"60 seconds\")\n",
    "    .foreachBatch(fine_tune)\n",
    "    .start()\n",
    ")\n",
    "\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
